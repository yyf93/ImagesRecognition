# ImagesRecognition

## 环境要求:
pip install flask opencv-python opencv-contrib-python torch face_recognition

## 项目简介:
人脸和图书的图像识别并分类.

## 选用技术
### opencv
#### 介绍
OpenCV是一个开源的计算机视觉库,其主要作用和使用场景如下:
1. 主要作用:
- 图像处理:涵盖各种图像处理操作,如滤波、 morphology、几何变换等。
- 特征检测和提取:支持各种特征检测算法,如 Harris角点检测、FAST角点检测、SIFT、SURF等。
- 对象检测:提供各种对象检测算法,如Haar特征检测、HOG + SVM、深度学习等。
- 机器学习:集成各种机器学习模型,如SVM、决策树、Boosting、神经网络等,用于计算机视觉任务。
- 视频分析:提供运动估计、背景减除、目标跟踪等算法,用于视频处理和理解。
- 相机校准和3D重建:包含各种相机模型、标定和立体匹配算法,用于3D视觉重建。
2. 主要使用场景:
- 人脸识别系统:使用Haar或深度学习特征检测人脸,结合机器学习模型实现识别。
- 目标跟踪系统:使用共轭梯度法或深度学习模型跟踪视频中的目标物体。
- 图像 stitching:使用SIFT或SURF特征配合Homography矩阵拼接多张图像。
- 3D重建系统:使用双目相机标定和立体匹配算法重建物体的3D结构。
- 机器视觉产品:各种具备图像处理、理解和交互能力的智能产品,如无人车、智能摄像头等。 
- 交通监控系统:检测和跟踪摄像头视野中的车辆,监控交通状况。
- 人数统计系统:采用目标检测和跟踪算法统计区域内的人流量和密度。
所以,OpenCV是一个功能强大的开源计算机视觉库,学习曲线较陡峭,需要一定的理论基础,但可以实现各种视觉功能和算法。特别适用于研究、定制化开发高难度视觉系统。

#### 分类器
1. KNN(K近邻分类器):
- 优点:简单、易于理解和实现。无需训练,直接基于样本进行分类。
- 缺点:分类速度慢、对高维空间的数据集性能较差。
2. SVM(支持向量机):
- 优点:泛化能力强、对高维空间的样本集也有很好的表现。
- 缺点:算法复杂度较高、训练时间长、对参数选择较为敏感。
3. Decision Trees(决策树):
- 优点:计算复杂度不高,易于理解和解释。无需调优参数。
- 缺点:容易过拟合、预测结果不够精确。
4. Naive Bayes(朴素贝叶斯):
- 优点:模型简单、易于实现、无需调优参数。训练速度快。
- 缺点:假设属性条件独立,这会影响预测精度。
5. Boosting(提升方法,如AdaBoost):
- 优点:可以减少过拟合,提高分类精度。
- 缺点:算法比较复杂,训练速度慢、容易过拟合。
6. Bagging(Bootstrap Aggregating,如Random Forest):
- 优点:稳定性好、准确性高、对没有标记数据也有较好效果。
- 缺点:算法比较复杂,训练速度慢。
综上,可以看出每种分类器都有其优缺点,可以根据实际应用选择合适的模型。如果准确性要求高可以选择SVM或Boosting方法;如果速度要求较高可以选择KNN或Naive Bayes。

#### 特征提取
1. SIFT(Scale-Invariant Feature Transform):
- 优点:识别性能最好,尺度和旋转不变性好。
- 缺点:速度慢,特征点较少。
2. SURF(Speeded Up Robust Features): 
- 优点:比SIFT快,识别性能也很好,尺度和旋转不变性良好。
- 缺点:特征维数高,计算量大,有专利限制。
3. ORB(Oriented FAST and Rotated BRIEF):
- 优点:速度最快,特征点最多,无专利限制。 
- 缺点:特征描述子只有256维,识别性能略差。
4. BRISK(Binary Robust Invariant Scalable Keypoints):
- 优点:快于SIFT和SURF,特征点集密集,有缩放不变性。
- 缺点:特征描述子512维,识别性能差一点。
5. FREAK(Fast Retina Keypoint): 
- 优点:FAST特征点和RETINA描述子,速度很快。 
- 缺点:特征描述子只有512维,识别性能稍差。
6. AKAZE(Accelerated KAZE): 
- 优点:速度快,有尺度和旋转不变性。 
- 缺点:特征点较少,在某些图像上效果稍差。
7. KAZE:
- 优点:识别性能高,有尺度和旋转不变性。 
- 缺点:速度慢,特征点也较少。
综上,不同算法在速度、特征点密集度和识别性能上都有取舍。可以根据实际应用选择合适的算法。一般来说,SIFT、SURF和KAZE识别性能好;ORB和BRISK速度快。

#### 代码实现
1. 初始化ORB和SIFT特征提取器,以及KNN和SVM模型。设置特征数量等参数。
2. 遍历所有训练图片,提取SIFT特征并转为numpy数组保存。同时记录图片类别标签。
3. 使用提取的SIFT特征和类别标签训练KNN和SVM模型。
4. 将训练好的模型保存为.xml文件,以便之后加载使用。

### torch
#### 介绍
PyTorch是一个流行和功能强大的深度学习框架,其主要作用和使用场景如下:
1. 主要作用:
- 搭建深度学习模型:提供丰富的模型构建模块,如卷积层、池化层、线性层、LSTM层等。
- 自动求导:可以自动计算模型的参数梯度,用于反向传播和参数更新。
- GPU加速:利用GPU显卡加速模型训练和预测,实现更高效的深度学习。
- 灵活的研究平台:PyTorch非常灵活,适用于深度学习的研究和创新。许多新的模型都是在PyTorch上先实现的。
2. 主要使用场景:
- 图像分类:使用CNN类模型实现dog/cat等多分类任务。
- 物体检测:使用faster RCNN、YOLO等模型检测图像中的物体。 
- 语义分割:使用FPN、U-Net等模型对图像进行像素级分割。
- 人脸识别:使用ResNet等模型构建人脸识别系统。
- 机器翻译:使用Transformer、LSTM等模型实现机器翻译。 
- 语音识别:使用CNN和RNN模型识别和转换语音信号。
- 目标跟踪:使用深度学习方法实现物体跟踪系统。
- Anomaly detection:使用深度学习检测时间序列等中的异常点。
- 时序预测:使用LSTM等模型预测时间序列的未来值。
- 聊天机器人:使用Seq2Seq等模型实现聊天机器人。
PyTorch是一个优秀的深度学习研究工具和产业化框架。许多大公司如Facebook,Tesla,Uber等都选择PyTorch作为深度学习平台。如果你想学习深度学习或研究最新模型,PyTorch是一个很好的选择。
如果你想将深度学习应用于产业,PyTorch也同样可以胜任,支持高性能的模型部署和部署。

#### 分类器
1. nn.Linear:全连接层,实现线性分类。
- 优点:简单、训练速度快。
- 缺点:分类效果较差,容易过拟合。
2. nn.Softmax:Softmax分类器,输出概率分布。
- 优点:简单,输出有意义的概率。
- 缺点:和nn.Linear一样,分类效果较差,容易过拟合。
3. nn.Conv2d:卷积层,可以构建CNN分类器。
- 优点:分类效果好,抗过拟合。
- 缺点:模型复杂,训练速度慢,需要大量数据集。
4. nn.RNN/LSTM/GRU:循环神经网络,用于序列分类。
- 优点:对序列数据有很好的效果,抗过拟合。
- 缺点:模型复杂,训练速度慢,需要大量标注数据。
5. nn.BatchNorm1d/2d:批标准化层,加速模型收敛,提高分类精度。
- 优点:收敛速度快,提高模型泛化能力,抗过拟合。
- 缺点:增加模型复杂度。
除此之外,PyTorch还提供了许多经典模型,如ResNet、Inception等,这些模型的分类效果都非常好,并且有预训练模型可以直接使用,实现迁移学习。
综上,如果追求速度和简单可以选择线性层或Softmax;如果要高精度分类可以选择CNN或RNN,并且配合BatchNorm使用,可以大大提高效果。此外,迁移学习是图像分类的有效方法,可以选择预训练模型并微调。

#### 特征提取
1. nn.Conv2d:卷积层,可以提取图像的低层特征。
- 优点:模型简单,特征具有平移不变性。
- 缺点:仅能提取低层特征,分类效果较差。
2. nn.MaxPool2d:最大值池化层,用于减少特征维度。
- 优点:加速计算,防止过拟合。
- 缺点:损失部分信息,特征表达能力下降。
3. nn.AdaptiveMaxPool2d:自适应最大值池化层,可以保留重要特征。
- 优点:减少特征维度,同时保留重要特征,防止过拟合。
- 缺点:实现复杂,速度略慢。
4. nn.ReLU/LeakyReLU/PReLU:激活函数,引入非线性,提高模型表达能力。 
- 优点:提高特征表达能力,防止线性特征的限制。
- 缺点:增加模型复杂度,需要调参。
5. ResNet/Inception等:使用这些模型可以提取图像的高阶特征,实现迁移学习。
- 优点:特征丰富,分类效果好,提供预训练模型方便使用。
- 缺点:模型复杂,训练资源消耗大。
6. nn.BatchNorm2d:批标准化,加速模型收敛,同时提高特征表达。
- 优点:收敛速度快,提高特征表达能力和泛化能力。
- 缺点:增加模型复杂度。
综上,低层特征具有位置不变性但表达能力差;高阶特征丰富但模型复杂。可以根据实际应用选择简单的卷积层和池化层,或 ResNet/Inception等模型进行迁移学习。BatchNorm又可以进一步提高模型效果。

#### 代码实现
1. 加载预训练的ResNet50模型,并移除最后的全连接层。
2. 提取所有训练图片的特征,并记录对应类别标签。
3. 将提取的特征和标签合并为Tensor,定义分类器模型(全连接层)。
4. 定义损失函数(CrossEntropyLoss)和优化器(Adam),并训练分类器模型。
5. 保存训练好的分类器模型。

### face_recognition

#### 介绍
face_recognition是一个非常易用的人脸识别库,其主要作用和使用场景如下:
1. 主要作用:
- 人脸检测:能够检测图像或视频中的人脸。
- 人脸特征提取:从检测到的人脸中提取128维的特征编码。
- 人脸识别:使用KNN模型将提取的特征与已知人脸数据库进行匹配,实现人脸识别。
- 人脸比对:计算两张人脸图像之间的距离,判断是否为同一人。
2. 主要使用场景:
- 人脸登录系统:使用人脸特征进行登录验证,替代传统账号密码方式。
- 人脸考勤系统:通过人脸识别判断员工是否到岗,实现自动考勤。
- 智能门禁系统:使用人脸识别开门,管理门禁权限。
- 情感分析:分析人脸表情,判断情绪趋势,为客户服务提供支持。
- 智能摄像头:检测图像或视频流中的人脸,抓拍或定时拍照,记录人员出入信息。
- 智能相册:能够自动对上传的人像照片进行人脸检测、识别和分类,实现智能管理相册。
- 机器人视觉:进行人脸检测和识别,帮助机器人理解人类视觉信息,实现更智能的交互。
- 机器视觉数据集标注:使用人脸检测自动定位人脸区域,辅助人工标注,提高效率。
所以,face_recognition是一个功能实用的人脸识别库,使用简单,无需深入了解机器学习理论和模型训练细节,可以快速上手并应用于各种人脸识别场景,特别适合产品开发和工程应用。

#### 代码实现
1. 遍历所有人脸图像,使用face_recognition检测人脸并提取特征编码。同时记录图像对应的人名标签。
2. 收集所有图像的人脸特征编码和对应的人名,用于之后的模型训练。
3. 注释中的代码使用face_recognition直接对图像进行分类和识别。该库已经内置了KNN模型,可以直接使用。
4. 将训练数据保存为.npy文件,以便之后加载识别新的人脸图像。

### yolov5 (调研ING)

### opencv, torch, face_recognition人脸比对
1. face_recognition
- 优点:易用性高,无需关注模型训练细节,识别速度快,适用于实时应用。
- 缺点:定制性差,不能训练自定义模型,识别效果可能不如高级模型。
2. OpenCV
- 优点:功能全面底层,可以定制各种模型,实现更高精度识别。
- 缺点:学习曲线陡峭,使用和开发难度较大,速度慢,不太适合实时应用。
3. PyTorch
- 优点:功能强大,可以构建各种深度学习模型,实现最高精度识别。
- 缺点:学习门槛高,需要精通深度学习和PyTorch,开发难度最大,速度也较慢。
所以总体来说:
- 如果追求易用性和速度,face_recognition是首选。
- 如果想研究算法或开发高精度识别系统,OpenCV和PyTorch更加适用。但难度也更大。
- 三者也可以很好结合:
  - 使用face_recognition检测人脸和提取特征。
  - 使用OpenCV或PyTorch训练模型进行识别。
  - 这样可以兼顾易用性、速度和效果。
对比三者对人脸识别的支持:
- face_recognition:主要支持人脸识别,内置KNN模型,无需关注训练细节。
- OpenCV:支持人脸检测、识别、特征提取等,需要自己定义和训练模型。
- PyTorch:可以构建各种深度学习模型,如CNN、ResNet等,实现人脸识别和其他视觉任务。需要有深度学习基础。

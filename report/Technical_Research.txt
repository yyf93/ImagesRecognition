图像分类:
单标签的图像分类问题，它可以分为跨物种语义级别的图像分类，子类细粒度图像分类，以及实例级图像分类三大类别
1.跨物种语义级别的图像分类 所谓跨物种语义级别的图像分类，它是在不同物种的层次上识别不同类别的对象，比较常见的包括如猫狗分类等。
这样的图像分类，各个类别之间因为属于不同的物种或大类，往往具有较大的类间方差，而类内则具有较小的类内误差。
2.子类细粒度图像分类 细粒度图像分类，相对于跨物种的图像分类，级别更低一些。它往往是同一个大类中的子类的分类，如不同鸟类的分类，不同狗类的分类，不同车型的分类等。
3.实例级图像分类 如果我们要区分不同的个体，而不仅仅是物种类或者子类，那就是一个识别问题，或者说是实例级别的图像分类，最典型的任务就是人脸识别

通常图像分类任务存在以下技术难点：
（1）视角变化：同一个物体，摄像机可以从多个角度来展现。
（2）大小变化：物体可视的大小通常是会变化的。
（3）形变：很多东西的形状并非一成不变，会有很大变化。
（4）遮挡：目标物体可能被挡住。有时候只有物体的一小部分是可见的。
（5）光照条件：在像素层面上，光照的影响非常大。
（6）背景干扰：物体可能混入背景之中，使之难以被辨认。
（7）类内差异：一类物体的个体之间的外形差异很大，比如椅子。这一类物体有许多不同的对象，每个都有自己的外形。

图像分类算法通过手工特征或者特征学习方法对整个图像进行全局描述，然后使用分类器判断是否存 在某类物体。
应用比较广泛的图像特征有SIFT，HOG，SURF等。这些对图像分类的研究中，大多数特征提取过程是人工设计的， 通过浅层学习获得图像底层特征，
与图像高级主题间还存在很大的“语义鸿沟” 。而深度学习利用设定好的网络结构， 完全从训练数据中学习图像的层级结构性特征，
能够提取更加接近图像高级语义的抽象特征，在图像识别上的表现远远超过传统方法，因此这里只关注于深度学习的进展。

卷积神经网络在特征表示上具有极大的优越性，模型提取的特征随着网络深度的增加越来越抽象，越来越能表现图像主题语义，
不确定性越少，识别能力越强。虽然基本的图像分类任务，尤其是比赛趋近饱和，但是现实中的图像任务仍然有很多的困难和挑战。
如类别不均衡的分类任务，类内方差非常大的细粒度分类任务，以及包含无穷负样本的分类任务。


```
sift = cv2.SIFT_create(nfeatures=features)
kps, dess = sift.detectAndCompute(image, None)
```
为啥一般OpenCV的SIFT特征检测算法使用descriptors去做图像比对，而不是用keypoints？
1.
返回特征点keypoints(kps)和对应的描述符descriptors(dess)
那么,这个函数的具体返回值是:
keypoints: 是一个list,len(keypoints)为检测到的特征点数量。每个元素是一个cv2.KeyPoint对象,包含该点的位置、尺度、方向等信息。
descriptors: 是一个NumPy数组,形状为( len(keypoints), 128 )。对应于每个特征点提取的128维SIFT描述符。
所以,这个函数的返回值包含了图像的SIFT特征点信息和描述符信息,我们可以使用这些信息进行图像配准(通过特征点匹配)、物体识别(通过特征点聚类)等计算机视觉任务。
2.
    1. keypoints只包含特征点的位置和方向信息,无法表达特征点周围的纹理和颜色信息。而SIFT描述符是通过周围的像素强度信息计算得到的,包含了较丰富的信息,更加适合用于图像配准和匹配。
    2. 当图像有过大姿态变化、尺度变化时,仅使用位置信息很难找到正确的匹配点,检测的特征点数量也会明显下降。而描述符包含的信息更加稳定,这种情况下的匹配效果会更好。
    3. 在图像中,某一局部区域内常常存在多个相似的特征点,仅根据位置难以区分。SIFT描述符考虑了更广域的像素信息,可以更好地刻画每个特征点,实现区分。
    4. SIFT描述符采用128维向量表示,空间上相当于一个128维空间中的一个点。在这个高维空间中,不同的描述符可以最大程度地分开,利于最近邻搜索和匹配。而2D图像坐标不具有这样的区分度。
    5. 相比坐标,SIFT描述符的计算更加耗时。所以检测keypoints可以快速地找到感兴趣区域,而描述符的计算可针对部分关键点进行以节省时间,这需要描述符来辅助判断哪些关键点最具有代表性。


为啥用Resnet152?
2015年，ResNet获得了分类任务冠军。它以3.57%的错误率表现超过了人类的识别水平，
并以152层的网络架构创造了新的模型记录。由于ResNet采用了跨层连接的方式，
它成功的缓解了深层神经网络中的梯度消散问题，为上千层的网络训练提供了可能。

后期TODO：
2017年，也是ILSVRC图像分类比赛的最后一年，SeNet获得了冠军。
这个结构，仅仅使用了“特征重标定”的策略来对特征进行处理，通过学习获取每个特征通道的重要程度，
根据重要性去降低或者提升相应的特征通道的权重。

## 技术选型
### opencv
#### 介绍
OpenCV是一个开源的计算机视觉库,其主要作用和使用场景如下:
1. 主要作用:
- 图像处理:涵盖各种图像处理操作,如滤波、 morphology、几何变换等。
- 特征检测和提取:支持各种特征检测算法,如 Harris角点检测、FAST角点检测、SIFT、SURF等。
- 对象检测:提供各种对象检测算法,如Haar特征检测、HOG + SVM、深度学习等。
- 机器学习:集成各种机器学习模型,如SVM、决策树、Boosting、神经网络等,用于计算机视觉任务。
- 视频分析:提供运动估计、背景减除、目标跟踪等算法,用于视频处理和理解。
- 相机校准和3D重建:包含各种相机模型、标定和立体匹配算法,用于3D视觉重建。
2. 主要使用场景:
- 人脸识别系统:使用Haar或深度学习特征检测人脸,结合机器学习模型实现识别。
- 目标跟踪系统:使用共轭梯度法或深度学习模型跟踪视频中的目标物体。- 图像 stitching:使用SIFT或SURF特征配合Homography矩阵拼接多张图像。
- 3D重建系统:使用双目相机标定和立体匹配算法重建物体的3D结构。
- 机器视觉产品:各种具备图像处理、理解和交互能力的智能产品,如无人车、智能摄像头等。
- 交通监控系统:检测和跟踪摄像头视野中的车辆,监控交通状况。
- 人数统计系统:采用目标检测和跟踪算法统计区域内的人流量和密度。
所以,OpenCV是一个功能强大的开源计算机视觉库,学习曲线较陡峭,需要一定的理论基础,但可以实现各种视觉功能和算法。特别适用于研究、定制化开发高难度视觉系统。

#### 分类器
1. KNN(K近邻分类器):
- 优点:简单、易于理解和实现。无需训练,直接基于样本进行分类。
- 缺点:分类速度慢、对高维空间的数据集性能较差。
2. SVM(支持向量机):
- 优点:泛化能力强、对高维空间的样本集也有很好的表现。
- 缺点:算法复杂度较高、训练时间长、对参数选择较为敏感。
3. Decision Trees(决策树):
- 优点:计算复杂度不高,易于理解和解释。无需调优参数。
- 缺点:容易过拟合、预测结果不够精确。
4. Naive Bayes(朴素贝叶斯):
- 优点:模型简单、易于实现、无需调优参数。训练速度快。
- 缺点:假设属性条件独立,这会影响预测精度。
5. Boosting(提升方法,如AdaBoost):
- 优点:可以减少过拟合,提高分类精度。
- 缺点:算法比较复杂,训练速度慢、容易过拟合。
6. Bagging(Bootstrap Aggregating,如Random Forest):
- 优点:稳定性好、准确性高、对没有标记数据也有较好效果。
- 缺点:算法比较复杂,训练速度慢。
综上,可以看出每种分类器都有其优缺点,可以根据实际应用选择合适的模型。如果准确性要求高可以选择SVM或Boosting方法;如果速度要求较高可以选择KNN或Naive Bayes。

#### 特征提取
##### 目的和作用：
目的：特征提取旨在从原始图像数据中提取具有代表性的、可区分不同类别的特征，以便在后续的分类或识别任务中使用。

作用：降低维度：原始图像数据通常包含大量的冗余信息，通过特征提取可以减少特征维度，从而提高计算效率和降低存储需求。
增强可区分性：好的特征应该能够准确地表达不同类别之间的差异，使得分类器能够更好地区分不同的图像类别。
提取有意义的信息：特征提取方法能够从图像中提取出与任务相关的语义信息，例如颜色、纹理、边缘等。

##### 常用特征提取
1. SIFT(Scale-Invariant Feature Transform):
- 优点:识别性能最好,尺度和旋转不变性好。
- 缺点:速度慢,特征点较少。
2. SURF(Speeded Up Robust Features):
- 优点:比SIFT快,识别性能也很好,尺度和旋转不变性良好。
- 缺点:特征维数高,计算量大,有专利限制。
3. ORB(Oriented FAST and Rotated BRIEF):
- 优点:速度最快,特征点最多,无专利限制。
- 缺点:特征描述子只有256维,识别性能略差。
4. BRISK(Binary Robust Invariant Scalable Keypoints):
- 优点:快于SIFT和SURF,特征点集密集,有缩放不变性。
- 缺点:特征描述子512维,识别性能差一点。
5. FREAK(Fast Retina Keypoint):
- 优点:FAST特征点和RETINA描述子,速度很快。
- 缺点:特征描述子只有512维,识别性能稍差。
6. AKAZE(Accelerated KAZE):
- 优点:速度快,有尺度和旋转不变性。
- 缺点:特征点较少,在某些图像上效果稍差。
7. KAZE:
- 优点:识别性能高,有尺度和旋转不变性。
- 缺点:速度慢,特征点也较少。
综上,不同算法在速度、特征点密集度和识别性能上都有取舍。可以根据实际应用选择合适的算法。一般来说,SIFT、SURF和KAZE识别性能好;ORB和BRISK速度快。

#### opencv中的SIFT特征提取， 提取RGB的还是灰度图像呢， 分别有什么优劣
##### RGB图像的SIFT特征提取优势：
颜色信息丰富：RGB图像包含了红、绿、蓝三个颜色通道，提供了更多的颜色信息，可以在特征提取过程中利用这些颜色信息。
目标识别：对于某些应用场景，颜色可能是识别和区分不同目标的关键因素，因此在这些情况下使用RGB图像进行SIFT特征提取可能更有优势。
##### RGB图像的SIFT特征提取劣势：
计算复杂度高：由于RGB图像具有三个通道，每个通道上都要计算SIFT特征，因此相对于灰度图像，计算复杂度会更高。
对光照变化敏感：RGB图像中的颜色信息可能受到光照变化的影响，这可能会导致特征提取的不稳定性。

##### 灰度图像的SIFT特征提取优势：
简化计算：灰度图像只包含一个通道，因此计算SIFT特征的复杂度相对较低，处理速度可能更快。
光照不变性：灰度图像对光照变化更具有稳定性，这意味着提取的特征可能对光照变化更不敏感。
##### 灰度图像的SIFT特征提取劣势：
颜色信息丢失：灰度图像中没有颜色信息，这可能导致在某些应用场景中丢失了关于目标的有用信息，例如特定颜色的目标识别。
总的来说，选择RGB图像还是灰度图像进行SIFT特征提取取决于具体的应用场景和任务需求。如果颜色对于目标识别和分类很重要，或者需要利用颜色信息进行进一步的处理，那么选择RGB图像可能更合适。如果希望简化计算过程、提高计算效率，并且对光照变化更稳定，那么选择灰度图像可能更合适。

#### 代码实现
1. 初始化ORB和SIFT特征提取器,以及KNN和SVM模型。设置特征数量等参数。
2. 遍历所有训练图片,提取SIFT特征并转为numpy数组保存。同时记录图片类别标签。
3. 使用提取的SIFT特征和类别标签训练KNN和SVM模型。
4. 将训练好的模型保存为.xml文件,以便之后加载使用。

### torch
#### 介绍
PyTorch是一个流行和功能强大的深度学习框架,其主要作用和使用场景如下:
1. 主要作用:
- 搭建深度学习模型:提供丰富的模型构建模块,如卷积层、池化层、线性层、LSTM层等。
- 自动求导:可以自动计算模型的参数梯度,用于反向传播和参数更新。
- GPU加速:利用GPU显卡加速模型训练和预测,实现更高效的深度学习。
- 灵活的研究平台:PyTorch非常灵活,适用于深度学习的研究和创新。许多新的模型都是在PyTorch上先实现的。
2. 主要使用场景:
- 图像分类:使用CNN类模型实现dog/cat等多分类任务。
- 物体检测:使用faster RCNN、YOLO等模型检测图像中的物体。
- 语义分割:使用FPN、U-Net等模型对图像进行像素级分割。
- 人脸识别:使用ResNet等模型构建人脸识别系统。
- 机器翻译:使用Transformer、LSTM等模型实现机器翻译。
- 语音识别:使用CNN和RNN模型识别和转换语音信号。
- 目标跟踪:使用深度学习方法实现物体跟踪系统。
- Anomaly detection:使用深度学习检测时间序列等中的异常点。
- 时序预测:使用LSTM等模型预测时间序列的未来值。
- 聊天机器人:使用Seq2Seq等模型实现聊天机器人。
PyTorch是一个优秀的深度学习研究工具和产业化框架。许多大公司如Facebook,Tesla,Uber等都选择PyTorch作为深度学习平台。如果你想学习深度学习或研究最新模型,PyTorch是一个很好的选择。
如果你想将深度学习应用于产业,PyTorch也同样可以胜任,支持高性能的模型部署和部署。

#### 分类器
1. nn.Linear:全连接层,实现线性分类。
- 优点:简单、训练速度快。
- 缺点:分类效果较差,容易过拟合。
2. nn.Softmax:Softmax分类器,输出概率分布。
- 优点:简单,输出有意义的概率。
- 缺点:和nn.Linear一样,分类效果较差,容易过拟合。
3. nn.Conv2d:卷积层,可以构建CNN分类器。
- 优点:分类效果好,抗过拟合。
- 缺点:模型复杂,训练速度慢,需要大量数据集。
4. nn.RNN/LSTM/GRU:循环神经网络,用于序列分类。
- 优点:对序列数据有很好的效果,抗过拟合。
- 缺点:模型复杂,训练速度慢,需要大量标注数据。
5. nn.BatchNorm1d/2d:批标准化层,加速模型收敛,提高分类精度。
- 优点:收敛速度快,提高模型泛化能力,抗过拟合。
- 缺点:增加模型复杂度。
除此之外,PyTorch还提供了许多经典模型,如ResNet、Inception等,这些模型的分类效果都非常好,并且有预训练模型可以直接使用,实现迁移学习。
综上,如果追求速度和简单可以选择线性层或Softmax;如果要高精度分类可以选择CNN或RNN,并且配合BatchNorm使用,可以大大提高效果。此外,迁移学习是图像分类的有效方法,可以选择预训练模型并微调。

#### 特征提取
1. nn.Conv2d:卷积层,可以提取图像的低层特征。
- 优点:模型简单,特征具有平移不变性。
- 缺点:仅能提取低层特征,分类效果较差。
2. nn.MaxPool2d:最大值池化层,用于减少特征维度。
- 优点:加速计算,防止过拟合。
- 缺点:损失部分信息,特征表达能力下降。
3. nn.AdaptiveMaxPool2d:自适应最大值池化层,可以保留重要特征。
- 优点:减少特征维度,同时保留重要特征,防止过拟合。
- 缺点:实现复杂,速度略慢。
4. nn.ReLU/LeakyReLU/PReLU:激活函数,引入非线性,提高模型表达能力。
- 优点:提高特征表达能力,防止线性特征的限制。
- 缺点:增加模型复杂度,需要调参。
5. ResNet/Inception等:使用这些模型可以提取图像的高阶特征,实现迁移学习。
- 优点:特征丰富,分类效果好,提供预训练模型方便使用。
- 缺点:模型复杂,训练资源消耗大。
6. nn.BatchNorm2d:批标准化,加速模型收敛,同时提高特征表达。
- 优点:收敛速度快,提高特征表达能力和泛化能力。
- 缺点:增加模型复杂度。
综上,低层特征具有位置不变性但表达能力差;高阶特征丰富但模型复杂。可以根据实际应用选择简单的卷积层和池化层,或 ResNet/Inception等模型进行迁移学习。BatchNorm又可以进一步提高模型效果。

#### 代码实现
1. 加载预训练的ResNet152模型,并移除最后的全连接层。
2. 提取所有训练图片的特征,并记录对应类别标签。
3. 将提取的特征和标签合并为Tensor,定义分类器模型(全连接层)。
4. 定义损失函数(CrossEntropyLoss)和优化器(Adam),并训练分类器模型。
5. 保存训练好的分类器模型。

#### ResNet介绍
当涉及到深度学习中的图像分类模型时，ResNet-50（Residual Network）是一个非常流行和成功的模型之一。它是由微软研究院的研究团队于2015年提出的，并在ImageNet图像分类挑战赛上取得了非常出色的成绩。下面我会从基础开始，对ResNet-50进行详细讲解：

深度卷积神经网络（DCNN）基础：

卷积层：卷积神经网络使用卷积层来提取图像特征，通过滑动一个卷积核（一小块权重矩阵）在图像上进行卷积操作，从而捕捉图像的局部特征。
激活函数：激活函数引入非线性性，帮助网络学习更复杂的特征表示。常用的激活函数包括ReLU（修正线性单元）和sigmoid等。
池化层：池化层用于降低特征图的空间维度，减少参数数量，同时保留关键特征。常见的池化操作是最大池化。
残差学习：

残差块：ResNet引入了残差块，通过跨层连接（跳跃连接）来解决深层网络训练中的梯度消失和表达能力受限的问题。残差块包括主路径和跳跃连接。主路径由一系列卷积层和激活函数组成，而跳跃连接直接将输入添加到主路径的输出上。
跳跃连接：跳跃连接允许信息在不同层之间直接传播，使得网络更容易学习到恒等映射（即无操作的特征提取）。
ResNet-50的结构：

深度：ResNet-50由50层组成，包括堆叠的残差块。
堆叠结构：ResNet-50按照一定的规律堆叠了多个残差块，形成更深的网络结构。具体而言，ResNet-50包括了几个不同层数的残差块堆叠，从低层到高层分别为3个残差块、4个残差块、6个残差块和3个残差块。
卷积层和池化层：在ResNet-50中，还包括一些卷积层和池化层用于图像的初始处理和特征提取。


#### 选用ResNet50的原因
ResNet50是一个深层的残差网络,相比传统CNN具有更好的图像分类性能,主要原因有:
1. 更深层次的网络可以学习更复杂的特征表示,达到更高的分类精度。然而,由于梯度消失问题,传统的深层CNN难以训练。ResNet通过引入残差连接,解决了这个问题,可以训练100+层的深度网络。
2. 残差连接可以实现特征重用,上层网络可以重用下层网络已经学习到的有用特征,而不需要完全重新学习,这提高了参数利用效率,减少了过拟合的可能性。
3. 残差块使得ResNet的参数数量大大减少。如果不使用残差连接,一个n层的CNN会比n个单层CNN的参数多n倍,这会导致严重的过拟合问题。残差连接可以重用下层特征,减少参数数量,控制模型复杂度。
##### 相比之下,传统的CNN通常只有20-30层,主要有以下特点:
1. 使用重复的卷积层和池化层提取图像特征,并逐渐抽象化。典型的网络结构为conv-relu-pool,重复多次。
2. 每一层网络都需要从输入图像完全重新学习特征,没有重用下层特征的机制,参数利用率较低。
3. 网络层数较浅, difícult 学习到复杂的高层特征,极限分类精度相对较低。
4. 网络参数较多,容易导致过拟合,要求更大的数据集进行训练。
所以,总体来说,ResNet50通过引入残差学习和特征重用的思想,构建了一个参数更少、层数更深的CNN,可以学习到更抽象和复杂的特征表示,达到更高的分类精度,同时控制过拟合,这使其在图像分类上表现优于传统的CNN模型。


### face_recognition
#### 流程
可视化流程如下:
       人脸数据库
         |
       人脸检测和编码
         |
     unknown_face_locations, unknown_encoding
         |
        编码匹配
         |
   判断属于匹配人脸的人


#### 介绍
face_recognition是一个非常易用的人脸识别库,其主要作用和使用场景如下:
1. 主要作用:
- 人脸检测:能够检测图像或视频中的人脸。
- 人脸特征提取:从检测到的人脸中提取128维的特征编码。
- 人脸识别:使用KNN模型将提取的特征与已知人脸数据库进行匹配,实现人脸识别。
- 人脸比对:计算两张人脸图像之间的距离,判断是否为同一人。
2. 主要使用场景:
- 人脸登录系统:使用人脸特征进行登录验证,替代传统账号密码方式。
- 人脸考勤系统:通过人脸识别判断员工是否到岗,实现自动考勤。
- 智能门禁系统:使用人脸识别开门,管理门禁权限。
- 情感分析:分析人脸表情,判断情绪趋势,为客户服务提供支持。
- 智能摄像头:检测图像或视频流中的人脸,抓拍或定时拍照,记录人员出入信息。
- 智能相册:能够自动对上传的人像照片进行人脸检测、识别和分类,实现智能管理相册。
- 机器人视觉:进行人脸检测和识别,帮助机器人理解人类视觉信息,实现更智能的交互。
- 机器视觉数据集标注:使用人脸检测自动定位人脸区域,辅助人工标注,提高效率。
所以,face_recognition是一个功能实用的人脸识别库,使用简单,无需深入了解机器学习理论和模型训练细节,可以快速上手并应用于各种人脸识别场景,特别适合产品开发和工程应用。

#### 代码实现
1. 遍历所有人脸图像,使用face_recognition检测人脸并提取特征编码。同时记录图像对应的人名标签。
2. 收集所有图像的人脸特征编码和对应的人名,用于之后的模型训练。
3. 注释中的代码使用face_recognition直接对图像进行分类和识别。该库已经内置了KNN模型,可以直接使用。
4. 将训练数据保存为.npy文件,以便之后加载识别新的人脸图像。

### yolov8 (调研ING)

### opencv, torch, face_recognition人脸比对
1. face_recognition
- 优点:易用性高,无需关注模型训练细节,识别速度快,适用于实时应用。
- 缺点:定制性差,不能训练自定义模型,识别效果可能不如高级模型。
2. OpenCV
- 优点:功能全面底层,可以定制各种模型,实现更高精度识别。
- 缺点:学习曲线陡峭,使用和开发难度较大,速度慢,不太适合实时应用。
3. PyTorch
- 优点:功能强大,可以构建各种深度学习模型,实现最高精度识别。
- 缺点:学习门槛高,需要精通深度学习和PyTorch,开发难度最大,速度也较慢。
所以总体来说:
- 如果追求易用性和速度,face_recognition是首选。
- 如果想研究算法或开发高精度识别系统,OpenCV和PyTorch更加适用。但难度也更大。
- 三者也可以很好结合:
  - 使用face_recognition检测人脸和提取特征。
  - 使用OpenCV或PyTorch训练模型进行识别。
  - 这样可以兼顾易用性、速度和效果。
对比三者对人脸识别的支持:
- face_recognition:主要支持人脸识别,内置KNN模型,无需关注训练细节。
- OpenCV:支持人脸检测、识别、特征提取等,需要自己定义和训练模型。
- PyTorch:可以构建各种深度学习模型,如CNN、ResNet等,实现人脸识别和其他视觉任务。需要有深度学习基础。
